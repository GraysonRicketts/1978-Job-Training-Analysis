---
title: "Propensity Score Implementation"
author: "Grayson Ricketts"
date: "11/7/2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf', fig.path = 'Figs/',
                      fig.width = 8.5, fig.height = 5,
                      echo = TRUE, warnings = FALSE)

library(ggplot2)
theme_set(theme_minimal())

library("faraway")
library("RItools")
library("gbm")
library("optmatch")
```

```{r, echo=FALSE}
lalonde <- read.table("job_training_observational_data.txt", header = TRUE)

# Removes redundant variable already represented by TREAT
lalonde <- within(lalonde, rm("TYPE"))

# Keep RE78 seperate for analysis at the end
RE78 <- lalonde$RE78

# Removes the response variable so that the design is not biased by outcomes
lalonde <- within(lalonde, rm("RE78"))
```

# Logistic Regression of Propensity Scores

## Standard Model
```{r}
model <- glm(TREAT ~ . , family = binomial(link = "logit"), data = lalonde)
summary(model)
```
Warning message suggests the data is linearly seperable with respsect to TREAT. 

## Reduced Model
```{r}
# Reduces model based on non-significant predictors in full model
bad.factors <- c("NODEGREE", "EDUC", "RE74")
lalonde.reduced <- lalonde[ , !(names(lalonde) %in% bad.factors)]

model.reduced <- glm(TREAT ~ . , family = binomial(link = "logit"), data = lalonde.reduced)
summary(model.reduced)
```

## Model Checking

### Half-Normal Plot of Residuals
```{r}
halfnorm(residuals(model))
halfnorm(residuals(model.reduced))
```

### Chi-Squared Goodness-of-Fit-Test for Model
```{r}
pchisq(deviance(model), df.residual(model))
pchisq(deviance(model.reduced), df.residual(model.reduced))
```

### Hosmer-Lemeshow Test
```{r}
hosmerlem <- function (y, yhat, g = 10) {
   cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0, 1, 1/g)),
                  include.lowest = TRUE)
   obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
   expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
   chisq <- sum((obs - expect)^2 / expect)
   P <- 1 - pchisq(chisq, g - 2)
   c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(y = lalonde$TREAT, yhat = fitted(model))
hosmerlem(y = lalonde.reduced$TREAT, yhat = fitted(model.reduced))
```

### Summary of Model Checking
It appears that both models are accurate in their prediction. This can be seen in the low Chi-Squared probabilities of the standard Chi-Squared Goodness-of-Fit-Test and the Hosmer-Lemeshow test. However, the reduced model seems better, so that is what will be used for propensity score calculation.

## Using Estimated Propensity Scores to Create Predicted Values
```{r}
lalonde$propscore.log <- predict(model.reduced, type = "response")

ggplot(data = lalonde, aes(propscore.log, fill = factor(TREAT))) +
  geom_histogram(aes(y = ..density..), alpha = .5, position = "identity")

ggplot(data = lalonde, aes(propscore.log, fill = factor(TREAT))) +
  geom_histogram(alpha = .5, position = "identity")

sum(lalonde$propscore.log > 0.5 & lalonde$TREAT == 0)
sum(lalonde$propscore.log > 0.5 & lalonde$TREAT == 1)
```

# Generalized Boosted Model (GBM) Propensity Scores

```{r}
# Suggested parameters comes from Guo, 2001
model.generalized.suggested <- gbm(TREAT ~ . - (propscore.log) , 
                                   distribution = "bernoulli", 
                                   data = lalonde, 
                                   train.fraction = 0.5, 
                                   interaction.depth = 4, 
                                   shrinkage = 0.0005)
model.generalized.default <- gbm(TREAT ~ . - (propscore.log) , 
                                 distribution = "bernoulli", 
                                 data = lalonde)

summary(model.generalized.suggested)
summary(model.generalized.default)
```
The suggested parameters for the GBM produced better results so that is what was used to calculate the propensity scores for GBMs.

```{r}
lalonde$propscore.gbm <- predict(model.generalized.suggested, type = "response")
```


# Matching
```{r}
matches <- match_on(TREAT ~ propscore.log, data = lalonde)
match.pair <- pairmatch(matches, data = lalonde)
match.full <- fullmatch(matches, data = lalonde)
```

## Balance Testing
```{r}
(allbalance <- xBalance(TREAT ~ . - (propscore.log + propscore.gbm) , 
    data = lalonde, 
    report = c("chisquare.test", "std.diffs"), 
    strata = data.frame(original = factor("none"), match.pair, match.full)))
```
Full match has a p-value of 0.603 which indicates that using the full match sorts out the imbalances between treatment and control.

# Weighting

## Weights for ATE
```{r}
weight.ATE <- ifelse(lalonde$TREAT == 1, 1 / lalonde$propscore.log, 
                                     1 / (1 - lalonde$propscore.log))
gweight.ATE <- ifelse(lalonde$TREAT == 1, 1 / lalonde$propscore.gbm, 
                                     1 / (1 - lalonde$propscore.gbm))
```

## Check balance of weights
```{r}
summary(lm(RE75 ~ TREAT, data = lalonde, weights = weight.ATE))
summary(lm(RE75 ~ TREAT, data = lalonde, weights = gweight.ATE))
```
Balancing using wieghts seems to be really bad.

# Analysis

```{r}
# Add back RE78 for analysis
lalonde$RE78 <- RE78
```

## Matched Analysis
```{r}
predictor.match <- lm(lalonde$RE78 ~ lalonde$TREAT + match.full)
anova(predictor.match)
```
There is obviously some sort of significant relation, but we cannot do point estimate with the dataframe as it is. To compute point estimates we must drop the units in the control that are not good matches. After that is completed, then it is possible to do a t-test to get the estimates.

## Weighted Analysis
```{r}
predictor.weighted.log <- lm(RE78 ~ . - (propscore.log + propscore.gbm) ,
                             data = lalonde,
                             weights = weight.ATE)
summary(predictor.weighted.log)
confint(predictor.weighted.log)

predictor.weighted.gbm <- lm(RE78 ~ . - (propscore.log + propscore.gbm) ,
                             data = lalonde,
                             weights = gweight.ATE)
summary(predictor.weighted.gbm)
confint(predictor.weighted.gbm)
```

## Naive Analysis
```{r}
predictor.naive <- lm(RE78 ~ . - (propscore.log + propscore.gbm) , data = lalonde)
summary(predictor.naive)
confint(predictor.naive)
```

                          
                          