---
title: "Propensity Score Implementation"
author: "Grayson Ricketts"
date: "11/7/2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf', fig.path = 'Figs/',
                      fig.width = 8.5, fig.height = 5,
                      echo = TRUE, warnings = FALSE)

library(ggplot2)
theme_set(theme_minimal())
```

```{r, echo=FALSE}
df <- read.table("job_training_observational_data.txt", header = TRUE)

# Removes the response variable so that the design is not biased by outcomes
df <- within(df, rm("RE78"))

# Removes redundant variable already represented by TREAT
df <- within(df, rm("TYPE"))
```

# Logistic Regression of Propensity Scores

## Standard Model
```{r}
df <- within(df, rm("TYPE"))
model <- glm(TREAT ~ ., family = binomial(link = "logit"), data = df)
summary(model)
```

## Reduced Model
```{r}
# Reduces model based on non-significant predictors in full model
bad.factors <- c("NODEGREE", "EDUC", "RE74")
df.reduced <- df[ , !(names(df) %in% bad.factors)]

model.reduced <- glm(TREAT ~ ., family = binomial(link = "logit"), data = df.reduced)
summary(model.reduced)
```

## Model Checking

### Half-Normal Plot of Residuals
```{r}
library(faraway)
halfnorm(residuals(model))
halfnorm(residuals(model.reduced))
```

### Chi-Squared Goodness-of-Fit-Test with ANOVA
```{r}
anova(model, test = "Chisq")
anova(model.reduced, test = "Chisq")
```

### Chi-Squared Goodness-of-Fit-Test for Model
```{r}
sum(residuals(model, type = "pearson")^2)
deviance(model)
pchisq(deviance(model), df.residual(model))
pchisq(deviance(model.reduced), df.residual(model.reduced))
```

### Hosmer-Lemeshow Test
```{r}
hosmerlem <- function (y, yhat, g = 10) {
   cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0, 1, 1/g)),
                  include.lowest = TRUE)
   obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
   expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
   chisq <- sum((obs - expect)^2 / expect)
   P <- 1 - pchisq(chisq, g - 2)
   c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(y = df$TREAT, yhat = fitted(model))
hosmerlem(y = df$TREAT, yhat = fitted(model.reduced))
```

## Summary of Model Checking
It appears that both models are accurate in their prediction. This can be seen in the low Chi-Squared probabilities of the standard Chi-Squared Goodness-of-Fit-Test and the Hosmer-Lemeshow test.

## Using Estimated Propensity Scores to Create Predicted Values
```{r}
# Attach propensity score value to dataset

# TODO: Find better way to include estimated propensity score values

psvalue <- predict(model, type = "response")
psvalue.reduced <- predict(model.reduced, type = "response")

ggplot(df[df$RE74 < quantile(df$RE74, .98), ], aes(psvalue, fill = factor(TREAT))) +
  geom_histogram(aes(y = ..density..), alpha = .5, position = "identity")
ggplot(df[df$RE74 < quantile(df$RE74, .98), ], aes(psvalue.reduced, fill = factor(TREAT))) +
  geom_histogram(aes(y = ..density..), alpha = .5, position = "identity")
```

# Generalized Boosted Model (GBM) Propensity Scores

```{r}
library("gbm")

# Suggested comes from Guo, 2001
model.generalized.suggested <- gbm(TREAT ~ ., distribution = "bernoulli", data = df, 
                         train.fraction = 0.5, 
                         interaction.depth = 4, 
                         shrinkage = 0.0005)
model.generalized.default <- gbm(TREAT ~ ., distribution = "bernoulli", data=df)

summary(model.generalized.suggested)
summary(model.generalized.default)
```

